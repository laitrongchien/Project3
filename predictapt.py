# -*- coding: utf-8 -*-
"""PredictAPT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1svQuswh6NZ2uTe8kaOLfV4LieTSlBx4s
"""

import pandas as pd
import random
import networkx as nx
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

from google.colab import drive
drive.mount('/content/drive')

"""Read data common vunerabilities exposures"""

cves = pd.read_csv('/content/drive/MyDrive/Project3/cve.csv')
cves.head()

cves.isna().sum()

cves.dropna(how='any', inplace=True)
risk_probability = [cvss / 10 for cvss in cves['cvss']]
cves['risk_probability'] = risk_probability
cves['risk_probability'] = cves['risk_probability'].round(2)
cves.head(10)

cwes = pd.read_csv('/content/drive/MyDrive/Project3/cwes.csv')
cwes.head()

products = pd.read_csv('/content/drive/MyDrive/Project3/products.csv')
products.head()

products.dropna(how='any', inplace=True)
products.head()



# Get all CVEs for each product
cves_of_product = products.groupby('vulnerable_product')['cve_id'].agg(list).reset_index()
cves_of_product = cves_of_product.rename(columns={'cve_id': 'cve_list'})
# Print the CVEs
cves_of_product

merge_products = products.merge(cves, on='cve_id')
merge_products

group_data = merge_products.groupby('vulnerable_product').agg({
    'cve_id': list,
    'risk_probability': list
}).reset_index()
group_data

random_products = group_data.sample(n=2)
random_products

"""Create a graph from the dataset using NetworkX, example view graph"""

sample_graph = nx.Graph()
for _, row in random_products.iterrows():
    product = row['vulnerable_product']
    cve_list = row['cve_id']
    risk_list = row['risk_probability']
    sample_graph.add_node(product, node_type='Product')
    # Add nodes and edges for each CVE in the cve_list
    for cve, risk_prob in zip(cve_list, risk_list):
        sample_graph.add_node(cve, node_type='CVE')
        sample_graph.add_edge(product, cve, weight=risk_prob)

# Visualize the graph
# pos = nx.spring_layout(attack_graph)
# nx.draw(attack_graph, pos, with_labels=True, font_weight='bold')
# plt.show()
# Define a color map for node types
node_color_map = {'Product': 'blue', 'CVE': 'red'}

# Visualize the graph with customized parameters
pos = nx.spring_layout(sample_graph, seed=42)
node_color = [node_color_map[node_type] for node_type in nx.get_node_attributes(sample_graph, 'node_type').values()]
edge_color = 'gray'

plt.figure(figsize=(12, 8))
nx.draw(sample_graph, pos, with_labels=True, font_weight='bold', node_size=300, node_color=node_color, edge_color=edge_color, alpha=0.7)
edge_labels = nx.get_edge_attributes(sample_graph, 'weight')
nx.draw_networkx_edge_labels(sample_graph, pos, edge_labels=edge_labels)
plt.show()

attack_graphs = []

for _, row in group_data.iterrows():
    product = row['vulnerable_product']
    cve_list = row['cve_id']
    risk_list = row['risk_probability']
    attack_graph = nx.Graph()
    attack_graph.add_node(product, node_type='Product')
    # Add nodes and edges for each CVE in the cve_list
    for cve, risk_prob in zip(cve_list, risk_list):
        attack_graph.add_node(cve, node_type='CVE')
        attack_graph.add_edge(product, cve, weight=risk_prob)
    attack_graphs.append(attack_graph)
print(len(attack_graphs))

# risk_probability_value = cves[cves['cve_id'] == 'CVE-2016-0363']['risk_probability'].values[0]
# print(risk_probability_value)

"""Calculate risk probability of attack for each product"""

product_risk_level = {}

for attack_graph in attack_graphs:
  product_nodes = [node for node, data in attack_graph.nodes(data=True) if data.get('node_type') == 'Product']
  # print(product_nodes)

  for product_node in product_nodes:
    neighbors = attack_graph.neighbors(product_node)
    cve_nodes = [neighbor for neighbor in neighbors if attack_graph.nodes[neighbor]['node_type'] == 'CVE']
    # print(cve_nodes)
    risk_prob = [attack_graph[product_node][cve_node]['weight'] for cve_node in cve_nodes]
    # print(risk_prob)

    product_not_risk_probability = 1.0
    for prob in risk_prob:
      product_not_risk_probability *= (1 - prob)
    product_risk_probability = 1 - product_not_risk_probability

    product_risk_level[product_node] = product_risk_probability
# print(product_risk_level)

"""Label base on risk level"""

labels = []
for product_node, product_risk_prob in product_risk_level.items():
  if product_risk_prob < 0.4:
    labels.append('low')
  elif 0.4 <= product_risk_prob < 0.7:
    labels.append('medium')
  else:
    labels.append('high')
# print(labels)
group_data['risk_level'] = group_data['vulnerable_product'].map(dict(zip(product_risk_level.keys(), labels)))
group_data

import numpy as np
# Splitting Data into Training and Testing
label_encoder = LabelEncoder()
# group_data['risk_level'] = label_encoder.fit_transform(group_data['risk_level'])
X = group_data[['vulnerable_product', 'cve_id', 'risk_probability']]
print(X.dtypes)
y = group_data['risk_level']
# print(y.dtypes)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model architecture
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')  # Output layer with 3 nodes for risk_level
])

# Model compilation
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Model training
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)